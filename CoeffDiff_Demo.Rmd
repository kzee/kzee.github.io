---
title: "Testing for Differences between Two Coefficients"
output: 
  html_document:
    toc: true
    toc_float: false
---

<font size="3">

```{r echo = F}
knitr::opts_chunk$set(message = F, cache = T, warning = F)  
```

<br>

# Overview

In this demo, we will discuss how to test whether two regression coefficients differ signficantly from each other. 

The reason for conducting such an analysis is that in psychology (and other disciplines) we sometimes want to know whether the effect of our focal construct (or variable) is a better predictor of a particular outcome compared to another construct (or variable). As discussed in work by [Gelman & Stern (2006)](https://www.tandfonline.com/doi/abs/10.1198/000313006x152649), we cannot reach this conclusion using the traditional output of a regression model alone. They make the point that just because one variable significantly predicts the outcome and another does not, does not mean that the two variables are *significantly different from each other*. [Shrout & Yip-Bannicq (2017)](https://psycnet.apa.org/record/2016-59616-001) also reinforce this point and emphasize the importance of testing whether coefficients are significantly different from each other, not just from 0. 

<br>


# Dataset

As an example, we will use the `affect` dataset from the `psych` package in R. Generally speaking, this dataset contains variables corresponding to 5 scales from the Eysenck Personality Inventory and the Motivational State Questionnaire, which was administered twice. For the purposes of this demo, we will examine only extraversion (`ext`) and neuroticism (`neur`) scores as predictors, and tense arousal (`TA2`) from the second measurement occsion as the outcome. 

```{r library and data, echo = TRUE, results = 'hide', message = FALSE}
library(dplyr)
library(car)
library(psych)
```

```{r}
head(affect)
```

<br>

For the purposes of this demo, we will test a relatively hypothesis: Neuroticism (`neur`) is a significantly stronger predictor of tense arousal (`EA2`) than extraversion (`ext`). 

<br>

# Data Prep

We will first mean center our two predictors. 

```{r center}
affect$neur.c <- scale(affect$neur, center = T, scale = F)
affect$ext.c <- scale(affect$ext, center = T, scale = F)
```
<br>

# Model Fit

Next, we will fit a regression model in which tense arousal from the second measurement occasion is a function of neuroticism and extraversion.

```{r model}
fit <- lm(TA2 ~ neur.c + ext.c, data = affect) 
summary(fit)
```

<br>
The results indicate that neuroticism significantly predicts tense arousal, whereas extraversion does not. We also see that the size of the coefficient for neuroticism is larger than the coefficient for extraversion. Based on this, it would be tempting conclude that neuroticism is a "stronger" or "better" predictor of tense arousal. 

However, we actually cannot draw this conclusion based on this information alone, as discussed by [Gelman and Stern (2006)](https://www.tandfonline.com/doi/abs/10.1198/000313006x152649) and [Shrout and Yip-Bannicq (2017)](https://psycnet.apa.org/record/2016-59616-001).

<br>

# Testing Differences in Coefficients
To properly test our hypothesis, we need to test the difference in our coefficients directly. 

We will first do this using the `linearHypothesis` function from the `car` package. All we need to do is enter the name of our `lm` model object and the hypothesis we are interested in testing, as shown below.

```{r}
linearHypothesis(fit, "neur.c = ext.c")
```

Here, we see that although the effect of neuroticsm was significantly different from 0 and the effect of extraversion was not in our original model, we are unable to conclude that they are signficantly different *from each other.*

<br>


# Going Further: Estimate and CI of the Difference

Although we have now tested our hypothesis, there are still other things we might want to know. For example, the test we performed did not provide an estimate or confidence interval of the difference in these coefficients, which are suggested by Shrout & Yip-Bannicq (2017).

There are a few ways one could go about doing this, but I found it best to simply write my own function, thereby ensuring I could obtain all the information I wanted. 

The function below can be run so that estimates and tests of the difference between two coefficient can be obtained in a single line of code. 
```{r diff test function, tidy = F}
difftest_lm <- function(x1, x2, model){
  diffest <- summary(model)$coef[x1,"Estimate"]-summary(model)$coef[x2,"Estimate"]
  vardiff <- (summary(model)$coef[x1,"Std. Error"]^2 + 
                summary(model)$coef[x2,"Std. Error"]^2) - (2*(vcov(model)[x1, x2])) 
  # variance of x1 + variance of x2 - 2*covariance of x1 and x2
  diffse <- sqrt(vardiff)
  tdiff <- (diffest)/(diffse)
  ptdiff <- 2*(1-pt(abs(tdiff), model$df, lower.tail=T))
  upr <- diffest + 1.96*diffse
  lwr <- diffest - 1.96*diffse 
  df <- model$df
  return(list(est=round(diffest, digits =2), 
              t=round(tdiff, digits = 2), 
              p=round(ptdiff, digits = 4), 
              lwr=round(lwr, digits = 2), 
              upr=round(upr, digits = 2),
              df = df))
}
```

<br>

Let's apply the function to our example model:

```{r}
difftest_lm("neur.c", "ext.c", fit)
```

<br>

We see that the p-value matches the p-value we got using the `linearHypothesis` function. However, we are also now able to see that the estimated difference between extraversion and neuroticism is *b* = `r difftest_lm("neur.c", "ext.c", fit)$est`, and the 95% CI ranges from `r difftest_lm("neur.c", "ext.c", fit)$lwr` to `r difftest_lm("neur.c", "ext.c", fit)$upr`.

<br>

# Some Notes and Comments
As this example shows, even if one effect is significant and the other is not, they may not be significantly different from each other. There are also cases in which two effects are both significantly different from 0 but may (or may not) be significantly different from each other. Our interpretations of the data may change in important ways as a result of testing differences between coefficients.

Another thing to add is that in the example above, our predictors were measured on the same scale (i.e., they were measured in the same units) and had standard deviations that were of roughly similar size. However, this may not always be in the case. If predictors are measured on different scales, or have very different standard deviations, then one would want to put them on the same scale in order to test differences in their effects. This could involve, for example, standardizing all variables so that they are all in standard deviation units. 


</font> 
<font size="2"> 
*[View .Rmd source code](/Users/zeekatherine/Desktop/WorkSchool/kzee.github.io/CoeffDiff_Demo.Rmd){target="_blank"}*
</font> 
<font size="2"> 
\
*updated April 22, 2019*
</font> 

<br>

<font size="2"> 

&nbsp;
<hr />
<!--  <p> Copyright &copy; 2019 Katherine S. Zee. All rights reserved. </p>   -->
<p style="text-align: center;"><span style="color: #808080;"><em>kzee@psych.columbia.edu</em></span></p>
</font> 

<!-- Add icon library -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">

<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
<a href="https://twitter.com/KatherineZee?lang=en/" target="_blank" class="fab fa-twitter"></a>
<a href="https://github.com/kzee/" target="_blank" class="fab fa-github"></a>
<a href="https://osf.io/g579q" target="_blank" class="ai ai-osf ai-1x"></a> 
<a href="https://www.researchgate.net/profile/Katherine_Zee" target="_blank" class="fab fa-researchgate"></a>
</p>

<font size="2"> 
<p style="text-align: center;"><span style="color: #808080;">The material above reflects the best of my knowledge on this topic. Please be sure to check your results and code carefully.</span></p>
</font> 
