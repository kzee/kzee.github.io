<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Testing for Differences between Two Coefficients</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Katherine S. Zee</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="publications.html">Publications</a>
</li>
<li>
  <a href="teaching.html">Teaching</a>
</li>
<li>
  <a href="rcode.html">R Code</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li>
  <a href="files/KatherineZeeCV.pdf">CV</a>
</li>
<li>
  <a href="contact.html">Contact</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Testing for Differences between Two Coefficients</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#dataset">Dataset</a></li>
<li><a href="#data-prep">Data Prep</a></li>
<li><a href="#model-fit">Model Fit</a></li>
<li><a href="#testing-differences-in-coefficients">Testing Differences in Coefficients</a></li>
<li><a href="#going-further-estimate-and-ci-of-the-difference">Going Further: Estimate and CI of the Difference</a></li>
<li><a href="#bayesian-version">Bayesian Version</a></li>
<li><a href="#some-notes-and-comments">Some Notes and Comments</a></li>
</ul>
</div>

<p><font size="3"></p>
<p><br></p>
<div id="overview" class="section level1">
<h1>Overview</h1>
<p>In this demo, we will discuss how to test whether two regression coefficients differ signficantly from each other.</p>
<p>The reason for conducting such an analysis is that in psychology (and other disciplines) we sometimes want to know whether the effect of our focal construct (or variable) is a better predictor of a particular outcome compared to another construct (or variable). As discussed in work by <a href="https://www.tandfonline.com/doi/abs/10.1198/000313006x152649">Gelman &amp; Stern (2006)</a>, we cannot reach this conclusion using the traditional output of a regression model alone. They make the point that just because one variable significantly predicts the outcome and another does not, does not mean that the two variables are <em>significantly different from each other</em>. <a href="https://psycnet.apa.org/record/2016-59616-001">Shrout &amp; Yip-Bannicq (2017)</a> also reinforce this point and emphasize the importance of testing whether coefficients are significantly different from each other, not just from 0.</p>
<p><br></p>
</div>
<div id="dataset" class="section level1">
<h1>Dataset</h1>
<p>As an example, we will use the <code>affect</code> dataset from the <code>psych</code> package in R. Generally speaking, this dataset contains variables corresponding to 5 scales from the Eysenck Personality Inventory and the Motivational State Questionnaire, which was administered twice. For the purposes of this demo, we will examine only extraversion (<code>ext</code>) and neuroticism (<code>neur</code>) scores as predictors, and tense arousal (<code>TA2</code>) from the second measurement occasion as the outcome.</p>
<pre class="r"><code>library(dplyr)
library(car)
library(psych)</code></pre>
<pre class="r"><code>head(affect)</code></pre>
<pre><code>##   Study Film ext neur imp soc lie traitanx state1 EA1 TA1 PA1 NA1 EA2 TA2
## 1  maps    3  18    9   7  10   3       24     22  24  14  26   2   6   5
## 2  maps    3  16   12   5   8   1       41     40   9  13  10   4   4  14
## 3  maps    3   6    5   3   1   2       37     44   1  14   4   2   2  15
## 4  maps    3  12   15   4   6   3       54     40   5  15   1   0   4  15
## 5  maps    3  14    2   5   6   3       39     67  12  20   7  13  14  15
## 6  maps    1   6   15   2   4   5       51     38   9  14   5   1   7  12
##   PA2 NA2 state2 MEQ        BDI
## 1   7   4     NA  NA 0.04761905
## 2   5   5     NA  NA 0.33333333
## 3   3   1     NA  NA 0.19047619
## 4   0   2     NA  NA 0.38461538
## 5  16  13     NA  NA 0.38095238
## 6   2   2     NA  NA 0.23809524</code></pre>
<p><br></p>
<p>For the purposes of this demo, we will test a relatively straight-forward hypothesis: Neuroticism (<code>neur</code>) is a significantly stronger predictor of tense arousal (<code>EA2</code>) than extraversion (<code>ext</code>).</p>
<p><br></p>
</div>
<div id="data-prep" class="section level1">
<h1>Data Prep</h1>
<p>We will first mean center our two predictors.</p>
<pre class="r"><code>affect$neur.c &lt;- scale(affect$neur, center = T, scale = F)
affect$ext.c &lt;- scale(affect$ext, center = T, scale = F)</code></pre>
<p><br></p>
</div>
<div id="model-fit" class="section level1">
<h1>Model Fit</h1>
<p>Next, we will fit a regression model in which tense arousal from the second measurement occasion is a function of neuroticism and extraversion.</p>
<pre class="r"><code>fit &lt;- lm(TA2 ~ neur.c + ext.c, data = affect) 
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = TA2 ~ neur.c + ext.c, data = affect)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.7831  -3.4415  -0.2372   3.3699  15.7363 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 15.65364    0.26752  58.514   &lt;2e-16 ***
## neur.c       0.12294    0.05388   2.282   0.0232 *  
## ext.c        0.03204    0.06086   0.526   0.5990    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.86 on 327 degrees of freedom
## Multiple R-squared:  0.01573,    Adjusted R-squared:  0.009714 
## F-statistic: 2.614 on 2 and 327 DF,  p-value: 0.0748</code></pre>
<p><br> The results indicate that neuroticism significantly predicts tense arousal, whereas extraversion does not. We also see that the size of the coefficient for neuroticism is larger than the coefficient for extraversion. Based on this, it would be tempting conclude that neuroticism is a &quot;stronger&quot; or &quot;better&quot; predictor of tense arousal.</p>
<p>However, we actually cannot draw this conclusion based on this information alone, as discussed by <a href="https://www.tandfonline.com/doi/abs/10.1198/000313006x152649">Gelman and Stern (2006)</a> and <a href="https://psycnet.apa.org/record/2016-59616-001">Shrout and Yip-Bannicq (2017)</a>.</p>
<p><br></p>
</div>
<div id="testing-differences-in-coefficients" class="section level1">
<h1>Testing Differences in Coefficients</h1>
<p>To properly test our hypothesis, we need to test the difference in our coefficients directly.</p>
<p>We will first do this using the <code>linearHypothesis</code> function from the <code>car</code> package. All we need to do is enter the name of our <code>lm</code> model object and the hypothesis we are interested in testing, as shown below.</p>
<pre class="r"><code>linearHypothesis(fit, &quot;neur.c - ext.c = 0&quot;)</code></pre>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## neur.c - ext.c = 0
## 
## Model 1: restricted model
## Model 2: TA2 ~ neur.c + ext.c
## 
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1    328 7758.2                           
## 2    327 7722.8  1    35.421 1.4998 0.2216</code></pre>
<p>Here, we see that although the effect of neuroticsm was significantly different from 0 and the effect of extraversion was not in our original model, we are unable to conclude that they are signficantly different <em>from each other.</em></p>
<p><br></p>
</div>
<div id="going-further-estimate-and-ci-of-the-difference" class="section level1">
<h1>Going Further: Estimate and CI of the Difference</h1>
<p>Although we have now tested our hypothesis, there are still other things we might want to know. For example, the test we performed did not provide an estimate or confidence interval of the difference in these coefficients, which are suggested by Shrout &amp; Yip-Bannicq (2017).</p>
<p>There are a few ways one could go about doing this, but I found it best to simply write my own function, thereby ensuring I could obtain all the information I wanted.</p>
<p>The function below can be run so that estimates and tests of the difference between two coefficient can be obtained in a single line of code.</p>
<pre class="r"><code>difftest_lm &lt;- function(x1, x2, model){
  diffest &lt;- summary(model)$coef[x1,&quot;Estimate&quot;]-summary(model)$coef[x2,&quot;Estimate&quot;]
  vardiff &lt;- (summary(model)$coef[x1,&quot;Std. Error&quot;]^2 + 
                summary(model)$coef[x2,&quot;Std. Error&quot;]^2) - (2*(vcov(model)[x1, x2])) 
  # variance of x1 + variance of x2 - 2*covariance of x1 and x2
  diffse &lt;- sqrt(vardiff)
  tdiff &lt;- (diffest)/(diffse)
  ptdiff &lt;- 2*(1-pt(abs(tdiff), model$df, lower.tail=T))
  upr &lt;- diffest + 1.96*diffse
  lwr &lt;- diffest - 1.96*diffse 
  df &lt;- model$df
  return(list(est=round(diffest, digits =2), 
              t=round(tdiff, digits = 2), 
              p=round(ptdiff, digits = 4), 
              lwr=round(lwr, digits = 2), 
              upr=round(upr, digits = 2),
              df = df))
}</code></pre>
<p><br></p>
<p>Let's apply the function to our example model:</p>
<pre class="r"><code>difftest_lm(&quot;neur.c&quot;, &quot;ext.c&quot;, fit)</code></pre>
<pre><code>## $est
## [1] 0.09
## 
## $t
## [1] 1.22
## 
## $p
## [1] 0.2216
## 
## $lwr
## [1] -0.05
## 
## $upr
## [1] 0.24
## 
## $df
## [1] 327</code></pre>
<p><br></p>
<p>We see that the p-value matches the p-value we got using the <code>linearHypothesis</code> function. However, we are also now able to see that the estimated difference between extraversion and neuroticism is <em>b</em> = 0.09, and the 95% CI ranges from -0.05 to 0.24.</p>
<p><br></p>
</div>
<div id="bayesian-version" class="section level1">
<h1>Bayesian Version</h1>
<p>Thus far, we have focused on testing differences in coefficients using the Frequentist approach. However, a comparable analysis can also be performed using a Bayesian model. In fact, testing for differences in coefficients is arguably more straight-forward with Bayesian estimation. Because Bayesian estimation involves generating a distribution of possible values given the dataset (known as the <em>posterior distribution</em>) for each parameter, to get the difference in two coefficients we only need to take the difference of their posterior distributions.</p>
<p>First, we will estimate the same model in a Bayesian way using the <code>brms</code> package for R. Note that this package uses similar syntax to the <code>lm()</code> function we used to estimate our model before.</p>
<pre class="r"><code>library(brms)
bfit &lt;- brm(TA2 ~ neur.c + ext.c, data = affect, seed = 111) </code></pre>
<pre class="r"><code>summary(bfit)</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: TA2 ~ neur.c + ext.c 
##    Data: affect (Number of observations: 330) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    15.65      0.27    15.11    16.17 1.00     4258     2707
## neur.c        0.12      0.05     0.02     0.23 1.00     4192     2912
## ext.c         0.03      0.06    -0.10     0.16 1.00     4094     3136
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     4.87      0.19     4.52     5.26 1.00     3992     3092
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We see that, having used default (noninformative) priors in our Bayesian analysis, the estimates for <code>neur.c</code> and <code>ext.c</code> are essentially the same as those obtained in the Frequentist analysis.</p>
<p>We can now test for the difference in these coefficients. Here are two ways of doing this.</p>
<p>First, we can use the <code>hypothesis()</code> function from <code>brms</code>. This is a helpful and easy-to-use function, as all we need to do is feed in the name of the model object and specify the hypothesis we want to test.</p>
<pre class="r"><code>hypothesis(bfit, &quot;neur.c - ext.c = 0&quot;)</code></pre>
<pre><code>## Hypothesis Tests for class b:
##           Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio
## 1 (neur.c-ext.c) = 0     0.09      0.07    -0.05     0.24         NA
##   Post.Prob Star
## 1        NA     
## ---
## &#39;CI&#39;: 90%-CI for one-sided and 95%-CI for two-sided hypotheses.
## &#39;*&#39;: For one-sided hypotheses, the posterior probability exceeds 95%;
## for two-sided hypotheses, the value tested against lies outside the 95%-CI.
## Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
<p>Again, we see that the point estimate for the difference and the 95% credibility interval look similar to the results we found before.</p>
<p>A second approach simply involves going through the steps that <code>hypothesis()</code> uses under the hood: extracting the posterior distributions for both coefficients and then taking their difference.</p>
<p>To begin, we need to pull out the posterior samples from our model.</p>
<pre class="r"><code>bfit_post &lt;- posterior_samples(bfit)</code></pre>
<p>Next, we use simple subtraction to take the difference in the two posterior distributions of interest and compute the mean and 95% credibility interval of this difference. (Note that the variables referring to the posterior draws have the prefix &quot;b_&quot; added to them).</p>
<pre class="r"><code>bfit_diff &lt;- bfit_post$b_neur.c - bfit_post$b_ext.c
mean(bfit_diff) %&gt;% round(digits = 2)</code></pre>
<pre><code>## [1] 0.09</code></pre>
<pre class="r"><code>quantile(bfit_diff, probs = c(.025, .975)) %&gt;% round(digits = 2)</code></pre>
<pre><code>##  2.5% 97.5% 
## -0.05  0.24</code></pre>
<p>These results are the same as those obtained using the <code>hypothesis()</code> function.</p>
<p>A nice way to visualize the difference in <code>neur.c</code> and <code>ext.c</code> is to plot the posterior distributions for each coefficient, as well as the posterior distribution of their difference. The plots below show these distributions, along with the predicted mean value (dot) and 95% credibility interval (solid line along the x-axis). The zero line is emphasized with the dashed gray line.</p>
<p>With this visualization, we can see that there is a positive value for the difference of <code>neur.c</code> and <code>ext.c</code>, but that zero cannot be ruled out as a plausible value.</p>
<pre class="r"><code>postdensplot &lt;- function(m, var1, var2, name1, name2){
  require(brms)
  require(dplyr)
  var1name &lt;- noquote(paste(&quot;b_&quot;, var1, sep = &quot;&quot;))
  var2name &lt;- noquote(paste(&quot;b_&quot;, var2, sep = &quot;&quot;))
  mp &lt;- as.data.frame(posterior_samples(m))
  var1_post &lt;- dplyr::select(mp, var1name)
  var2_post &lt;- dplyr::select(mp, var2name)
  diff &lt;- as.data.frame(var1_post - var2_post)
  
  mpost_var1 &lt;- data.frame(post = var1_post, Coefficient = name1)
  colnames(mpost_var1) &lt;- c(&quot;post&quot;, &quot;Coefficient&quot;)
  mpost_var2 &lt;- data.frame(post = var2_post, Coefficient = name2)
  colnames(mpost_var2) &lt;- c(&quot;post&quot;, &quot;Coefficient&quot;)
  mpost_diff &lt;- data.frame(post = diff, Coefficient = paste(name1, name2, sep = &quot;-&quot;))
  colnames(mpost_diff) &lt;- c(&quot;post&quot;, &quot;Coefficient&quot;)
  mpost_long_df &lt;- rbind(mpost_var1, mpost_var2, mpost_diff)
  mpost_long_df &lt;- mpost_long_df %&gt;% group_by(Coefficient) %&gt;% 
    mutate(post_mean = mean(post), 
           post_lwr = quantile(post, probs = .025),
           post_upr = quantile(post, probs = .975),
           post_lwr90 = quantile(post, probs = .05),
           post_upr90 = quantile(post, probs = .95)) %&gt;% ungroup()
  
  require(ggplot2)
  myplot &lt;- ggplot(mpost_long_df, aes(x = post, fill = Coefficient)) +
    geom_density(color = &quot;white&quot;, alpha = .5) +
    geom_vline(xintercept = 0, color = &quot;gray50&quot;, linetype = &quot;dashed&quot;) +
    labs(x = &quot;\nCoefficient&quot;, y = &quot;Density\n&quot;) +
    scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;, &quot;gray30&quot;)) +
    scale_color_manual(values = c(&quot;blue3&quot;, &quot;red3&quot;, &quot;gray30&quot;)) +
    geom_segment(aes(x=post_lwr, xend=post_upr, y=.05, yend=.05, color = Coefficient), size = .2, alpha = .7) +
    geom_point(aes(x = post_mean, y = 0.05, color = Coefficient), size = 1, alpha = .8) +
    theme_bw() +
    theme(text=element_text(size=10)) +
    theme(legend.position=&quot;none&quot;) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
    facet_wrap(~Coefficient, ncol = 1, strip.position=&quot;top&quot;)
  return(myplot)
  
}
postdensplot(bfit, &quot;neur.c&quot;, &quot;ext.c&quot;, &quot;Neuroticism&quot;, &quot;Extraversion&quot;) + theme(text=element_text(size=12))</code></pre>
<p><img src="CoeffDiff_Demo_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="some-notes-and-comments" class="section level1">
<h1>Some Notes and Comments</h1>
<p>As this example shows, even if one effect is significant and the other is not, they may not be significantly different from each other. There are also cases in which two effects are both significantly different from 0 but may (or may not) be significantly different from each other. Our interpretations of the data may change in important ways as a result of testing differences between coefficients.</p>
<p>Another thing to add is that in the example above, our predictors were measured on the same scale (i.e., they were measured in the same units) and had standard deviations that were of roughly similar size. However, this may not always be in the case. If predictors are measured on different scales, or have very different standard deviations, then one would want to put them on the same scale in order to test differences in their effects. This could involve, for example, standardizing variables so that they are all in standard deviation units.</p>
<p></font> <font size="2"> <em><a href="/Users/zeekatherine/Desktop/WorkSchool/kzee.github.io/CoeffDiff_Demo.Rmd" target="_blank">View .Rmd source code</a></em> </font> <font size="2"><br />
<em>updated September 7, 2019</em> </font></p>
<p><br></p>
<p><font size="2"></p>
 
<hr />
<!--  <p> Copyright &copy; 2019 Katherine S. Zee. All rights reserved. </p>   -->
<p style="text-align: center;">
<span style="color: #808080;"><em><a href="mailto:kzee@psych.columbia.edu">kzee@psych.columbia.edu</a></em></span>
</p>
<p></font></p>
<!-- Add icon library -->
<p><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"></p>
<p><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous"></p>
<p><link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"></p>
<!-- Add font awesome icons -->
<p style="text-align: center;">
<a href="https://twitter.com/KatherineZee?lang=en/" target="_blank" class="fab fa-twitter"></a> <a href="https://github.com/kzee/" target="_blank" class="fab fa-github"></a> <a href="https://osf.io/g579q" target="_blank" class="ai ai-osf ai-1x"></a> <a href="https://www.researchgate.net/profile/Katherine_Zee" target="_blank" class="fab fa-researchgate"></a>
</p>
<font size="2">
<p style="text-align: center;">
<span style="color: #808080;">The material above reflects the best of my knowledge on this topic. Please be sure to check your results and code carefully.</span>
</p>
<p></font></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
