---
title: "Plotting Fixed Effect from Multilevel Models"
output: 
  html_document:
    toc: true
    toc_float: false
    includes:
      after_body: footer2.html
---
<font size="3">

```{r echo = F}
knitr::opts_chunk$set(message = F, cache = T, warning = F)  
```


This guide demonstrates how to plot a fixed (average) effect from a multilevel model in R. 

```{r libraries, echo = TRUE, results = 'hide', message = FALSE}
library(lme4)
library(lmerTest)
library(ggplot2)
library(bmlm)
library(brms) 
library(gridExtra)
```

<br>

### Load example dataset (from bmlm package)
For this demo, we will use the `BLch9` dataset available through the `bmlm` package for R. The `BLch9` dataset comes from the example used in Chapter 9 of *[Intensive Longitudinal Methods](http://www.intensivelongitudinal.com/){target="_blank"}* by Niall Bolger & J-P Laurenceau. (The book is great, by the way, and I highly recommend it.)

For details on this dataset, run `?BLch9`.

```{r load data}
d <- BLch9
```

<br>


## Frequentist Approach using `lme4`

### Fit example model 
First, we will fit a multilevel model in which `x` and `m` predict our outcome variable, `freldis`. We will include `x` and `m` as fixed effects and allow for each of these effects to vary between persons through the inclusion of random effect terms. 

Note that `x` and `m` have already been person-centered.

```{r model, echo = TRUE, results = 'hide', message = FALSE}
fit <- lmer(freldis ~ x + m + (x + m | id), data = d)
```

```{r model output}
summary(fit)
```

We can see from the model output that there is a significant effect of `x` on `freldis` for the typical person, adjusting for `m`. Now, we will plot this effect. 

<br>

### Create New Dataframe
To generate a plot of this effect, we want to use the model predicted values. To do this, we will first create new df with all observed values of `x`, with `m` held constant at 0 (indicating the mean value of `m` for each subject). We will have our new `x` consist of values falling in the observed range of values (i.e., from the minimum observed `x` in the dataset to the maximum observed `x` in the dataset). We will generate values in .01 unit increments. This will help ensure that the CIs will be smooth for plotting. 

```{r new dataframe}
mydata <- data.frame(
                     x = seq(min(d$x), max(d$x), .01),
                       m = 0
                       )

```

<br>

### Specify Design Matrix with Fixed Effects
Next, we will create a design matrix to obtain the fixed effect of `x`. 

```{r designmat}
fit.mat <- model.matrix(~ x + m, mydata) 
cis <- diag(fit.mat %*% tcrossprod(vcov(fit), fit.mat))
```

We will then use the new dataframe we created to predict values of our outcomes, `freldis`, from the model. Note that predictions for the lower and upper bounds of the 95% CI are generated in separate steps.

```{r predict_lmer}
# predict y values and lwr/upr bounds using model object and new data
mydata$freldis <- predict(fit, mydata, re.form = NA)
mydata$lwr <- mydata$freldis-1.96*sqrt(cis)
mydata$upr <- mydata$freldis+1.96*sqrt(cis)
```

<br>

### Plot Fixed Effect
Now, we will use the `ggplot2()` package to plot our results. We will plot the raw data points (jittered, whereby we introduce a small amount of random noise to prevent individual points from stacking on top of each other) in the first part of the code. In the second part of the code, we will then plot the model-predicted line and 95% CI showing the fixed effect of `x` on `freldis` controlling for `m`. 

<br>

```{r lmerplot, echo = TRUE, message = FALSE}
mlmplot <- ggplot(mydata, aes(x, freldis)) +
  geom_point(
    data = d,
    aes(x, freldis),
    position = position_jitter(h = 0.1, w = 0.2),
    alpha = .2,
    color = "black",
    size = .5
  ) +
  geom_ribbon(data = mydata, aes(ymin = lwr, ymax = upr),
              alpha = .3, fill = "red") +
  geom_line(data = mydata, aes(x, freldis), size = 1, color = "red") +
  xlim(-3, 3) +
  labs(x = "x (within-person centered)",
       y = "freldis",
       title = "lmer Version") +
  theme_bw() 
mlmplot
```

We have now plotted the fixed effect of `x` from our `lmer()` model, taking covariate `m` into account. 

<br>


## Bayesian Approach using `brms`

In this next part of the demo, we will fit the same model using Bayesian estimation with the `brms` package, and use the results of this model to plot the same fixed effect of `x` on `freldis` controlling for `m`. 

<br>

### Fit example model 

First, let's fit the model. We will fit the same model as above. The code is extremely similar to the code used to run our `lmer()` model. We will use the default (noninformative) priors from the package. 

Note that `brm()` models often take a few minutes to run. 

```{r fitbrms, results = "hide"}
fitb <- brms::brm(freldis ~ x + m + (x + m | id), data = d)
```

```{r summarybrms}
print(summary(fitb), digits = 3)
```

<br>

### Create New Dataframe
Now, we will create a new dataframe, similar to above. 

```{r}
mydatab <- data.frame(
  id = d$id,
  x = d$x,
  m = 0
)
```

Next, we will use the `fitted()` function in `brms` to generate predictions and the 95% credibility interval. We will append these predicted values to our `mydatab` dataframe. 

Note that `brms` features both a `fitted()` function and a `predict()` function, but they will return different information. The fitted line should be the same for both, but the credibility intervals differ. `fitted()` takes uncertainty of the estimation of the fitted line into account, whereas `predict()` takes into account both uncertainty about the estimation of the fitted line and uncertainty about the data. Thus, `predict()` in `brms` will yield a wider interval. `fitted()` closely matches the predicted interval we get from the `lmer()` model. 

```{r}
mydatab <- cbind(mydatab, fitted(fitb, mydatab, re_formula=NA))
colnames(mydatab) <- c("id", "x", "m", "estimate", "error", "lwr", "upr")
```

Now, we can use `ggplot2()` to plot the results.

```{r mlmplotb, echo = TRUE, message = FALSE}
mlmplotb <- ggplot(mydatab, aes(x, estimate)) +
  geom_point(
    data = d,
    aes(x, freldis),
    position = position_jitter(h = 0.1, w = 0.2),
    alpha = .2,
    color = "black",
    size = .5
  ) +
 geom_ribbon(data = mydatab, aes(ymin = lwr, ymax = upr),
             alpha = .3, fill = "red") +
  geom_line(data = mydatab, aes(x, estimate),
            size = 1, color = "red") +
  xlim(-3, 3) +
  labs(x = "x (within-person centered)",
       y = "freldis",
       title = "brms Version") +
  theme_bw() 
mlmplotb
```

<br>

## How do the plots using `lme4` and `brms` compare?
Now, let's compare the two plots side by side. 

```{r}
grid.arrange(mlmplot, mlmplotb, ncol = 2)
```

We find that in this case the fixed effect of `x` on `freldis` is essentially the same across the two types of models. 


<br>

## Wait, can't I just use the built-in functions available through `ggplot2()`?
At this point you may be asking yourself why we have to go to the bother of creating a new dataframe and using it to generate predictions from the model when `ggplot2()` offers features that allow us to to draw a regression line and add a confidence band. 

The answer is that ggplot does not "know" what is in our model. The exception is when you have a very simple model, such as x predicting y in a (non-multilevel) regression with no other variables. In this case, ggplot does not know that we used a multilevel model (observations nested within individuals), nor does it know that the effect of `x` is adjusting for a covariate, `m` in this case. 

Here's what we get when we simply use ggplot to generate our figure, without using the model to predict our fitted line and confidence band.


```{r plot_gg, echo = TRUE, message = FALSE}
plot_gg <- ggplot(d, aes(x, freldis)) +
  geom_point(position = position_jitter(h=0.1, w=0.2), 
             alpha=.2, color = "black", size = .5) +  
  geom_smooth(method='lm', size = 1, color = "red", fill = "red") + 

    labs(x = "x (within-person centered)",
       y = "freldis",
       title = "ggplot built-in lm()") + 
    xlim(-3, 3) +
  theme_bw()
plot_gg
```

<br>

When we view this plot next to the ones we generated previously, in which we used the model to generate the fitted line and confidence bands, we can see right away that the confidence band is too narrow and the slope of the fitted line is a little too steep.

```{r}
grid.arrange(plot_gg, mlmplot, mlmplotb, ncol = 3)
```

</font> 

<br>

<font size="2"> 
*[View .Rmd source code](/Users/zeekatherine/Desktop/WorkSchool/kzee.github.io/PlotFixef_Demo.Rmd){target="_blank"}*
</font> 
<font size="2"> 
\
*updated March 19, 2019*
</font> 